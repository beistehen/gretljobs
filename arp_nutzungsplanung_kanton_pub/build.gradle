
// Macht ein Datenumbau in die Struktur des Publikationsmodells (Schema "arp_nutzungsplanung_transfer_pub"). 
// Das resultierende XTF wird ins Schema "arp_nutzungsplanung_pub" importiert. Das Schema "arp_nutzungsplanung_transfer_pub" wird auch vom GRETL-Job arp_nutzungsplanung_pub verwendet.

import ch.so.agi.gretl.tasks.*
import ch.so.agi.gretl.api.TransferSet
import java.nio.file.Files
import java.nio.file.Paths
import java.io.File

apply plugin: 'ch.so.agi.gretl'

//Für Export AI
def pathToTempFolder = System.getProperty("java.io.tmpdir")
def dbSchemaLandUsePlansKanton = "arp_nutzungsplanung_kanton_v1"
def iliModelMgdm = "Nutzungsplanung_V1_2"
def dbSchemaMgdmLandUsePlans = "arp_nutzungsplanung_mgdm_v1"
def mgdmLandUsePlansXtfFileName = "ch.so.arp.npl.mgdm.kanton.xtf"
def mgdmLandUsePlansZipFileName = "ch.so.arp.npl.mgdm.kanton.zip"

//defaultTasks 'importXTF_stage', 'importXTF_pub', 'publish'
//defaultTasks 'uploadMgdmLandUsePlans'

task deleteData_transfer_pub (type: SqlExecutor) {
    description = "Löscht/leert die Daten aus dem Schema arp_nutzungsplanung_transfer_pub."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ["delete_arp_nutzungsplanung_transfer_pub.sql"]
}

task exportDataEdit (type: Ili2pgExport, dependsOn: 'deleteData_transfer_pub') {
    description = "Exportiert die Daten aus dem Schema arp_nutzungsplanung_kanton in ein INTERLIS-Datei."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    dbschema = 'arp_nutzungsplanung_kanton_v1'
    models = 'SO_ARP_Nutzungsplanung_Nachfuehrung_20221118'
    dataFile= file("kanton/kanton.xtf")
    disableValidation = true
}

task validateDataEdit(type: IliValidator, dependsOn: 'exportDataEdit') {
    description = "Validiert die exportierten INTERLIS-Datei gegen das Modell."
    dataFiles = file("kanton/kanton.xtf")
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    configFile = 'SO_ARP_Nutzungsplanung_Nachfuehrung_20221118.ini'
    allObjectsAccessible = true
    failOnError = true
}

task publishEdit(type: Publisher, dependsOn: validateDataEdit){
    dataIdent = 'ch.so.arp.nutzungsplanung.kantonal.relational'
    modelsToPublish = 'SO_ARP_Nutzungsplanung_Nachfuehrung_20221118'
    sourcePath = file("kanton/kanton.xtf")
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    target = ["sftp://$sftpServerSogis/$sftpUserSogis", sftpUserSogis, sftpPwdSogis]
    kgdiService = [simiMetadataServiceUrl, simiMetadataServiceUser, simiMetadataServicePwd]
    kgdiTokenService = [simiTokenServiceUrl, simiTokenServiceUser, simiTokenServicePwd]
    grooming = new File(file(rootDir).getParentFile(), "publisher_grooming.json")
}

task transferData(type: SqlExecutor, dependsOn: 'publishEdit') {
    description = "Führt den Datenumbau in das Schema arp_nutzungsplanung_transfer_pub durch. Das braucht es, damit ein XFT pro Dataser ins Schema arp_nutzungsplanung_pub importiert resp. ersetzt werden kann"
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ["insert_arp_nutzungsplanung_transfer_pub.sql"]
}

task exportData (type: Ili2pgExport, dependsOn: 'transferData') {
    description = "Exportiert die umgebauten Daten aus dem Schema arp_nutzungsplanung_transfer_pub in ein INTERLIS-Datei."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    dbschema = 'arp_nutzungsplanung_transfer_pub_v1'
    models = 'SO_ARP_Nutzungsplanung_Publikation_20201005'
    dataFile= file("kanton_pub/kanton_pub.xtf")
    disableValidation = true
}

task validateData(type: IliValidator, dependsOn: 'exportData') {
    description = "Validiert die exportierten INTERLIS-Datei gegen das Modell."
    dataFiles = file("kanton_pub/kanton_pub.xtf")
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    failOnError = true
}

task importXTF_stage(type: Ili2pgReplace, dependsOn: 'validateData') {
    description = 'Import der umgebaute INTERLIS-Datei "Kanton" in das Schema arp_nutzungsplanung_staging.'
    database = [dbUriPub, dbUserPub, dbPwdPub]
    dbschema = 'arp_nutzungsplanung_staging_v1'
    models = 'SO_ARP_Nutzungsplanung_Publikation_20201005'
    dataset = 'Kanton'
    dataFile = file("kanton_pub/kanton_pub.xtf")
    disableValidation = true
}

task delete_Dataset_stage(type: Ili2pgDelete) {
    description = "Löscht Daten mit Dataset= Kanton aus dem Schema arp_nutzungsplanung_staging"
    database = [dbUriPub, dbUserPub, dbPwdPub]
    models = 'SO_ARP_Nutzungsplanung_Publikation_20201005'
    dbschema = 'arp_nutzungsplanung_staging_v1'
    dataset = 'Kanton'
}

task importXTF_pub(type: Ili2pgReplace) {
    description = 'Import der umgebaute INTERLIS-Datei "Kanton" in das Schema arp_nutzungsplanung_pub.'
    database = [dbUriPub, dbUserPub, dbPwdPub]
    dbschema = 'arp_nutzungsplanung_pub_v1'
    models = 'SO_ARP_Nutzungsplanung_Publikation_20201005'
    dataset = 'Kanton'
    dataFile = file("kanton_pub/kanton_pub.xtf")
    disableValidation = true
    finalizedBy delete_Dataset_stage
}

task publishPub(type: Publisher, dependsOn: importXTF_pub){
    dataIdent = 'ch.so.arp.nutzungsplanung.kantonal'
    modelsToPublish = 'SO_ARP_Nutzungsplanung_Publikation_20201005'
    userFormats = true
    sourcePath = file("kanton_pub/kanton_pub.xtf")
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    target = ["sftp://$sftpServerSogis/$sftpUserSogis", sftpUserSogis, sftpPwdSogis]
    kgdiService = [simiMetadataServiceUrl, simiMetadataServiceUser, simiMetadataServicePwd]
    kgdiTokenService = [simiTokenServiceUrl, simiTokenServiceUser, simiTokenServicePwd]
    grooming = new File(file(rootDir).getParentFile(), "publisher_grooming.json")
}

// TASKS FÜR ALTES MODELL

task deleteData_export (type: SqlExecutor) {
    description = "Löscht/leert die Daten aus dem Schema arp_nutzungsplanung_export_v1."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ["delete_arp_nutzungsplanung_export.sql"]
}

task transferDataExport(type: SqlExecutor, dependsOn: 'deleteData_export') {
    description = "Führt den Datenumbau in das Schema arp_nutzungsplanung_export_v1 durch. Das braucht es, damit die Daten auch im alten Modell abgegeben werden können"
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ["insert_arp_nutzungsplanung_export_kanton_20222208.sql"]
}

task exportDataExport (type: Ili2pgExport, dependsOn: 'transferDataExport') {
    description = "Exportiert die umgebauten Daten aus dem Schema arp_nutzungsplanung_export_v1 in ein INTERLIS-Datei."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    dbschema = 'arp_nutzungsplanung_export_v1'
    models = 'SO_Nutzungsplanung_20171118'
    dataFile= file("kanton_alt/kanton_modell_2017.xtf")
    disableValidation = false
}

task publishAlt(type: Publisher, dependsOn: exportDataExport){
    dataIdent = 'ch.so.arp.nutzungsplanung.kantonal_modell_2017'
    modelsToPublish = 'SO_Nutzungsplanung_20171118'
    sourcePath = file("kanton_alt/kanton_modell_2017.xtf")
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    target = ["sftp://$sftpServerSogis/$sftpUserSogis", sftpUserSogis, sftpPwdSogis]
    kgdiService = [simiMetadataServiceUrl, simiMetadataServiceUser, simiMetadataServicePwd]
    kgdiTokenService = [simiTokenServiceUrl, simiTokenServiceUser, simiTokenServicePwd]
    grooming = new File(file(rootDir).getParentFile(), "publisher_grooming.json")
}

// EXPORT AI 

task deleteMgdmLandUsesPlansData(type: SqlExecutor) {
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ['truncate_all_arp_npl_mgdm_tables.sql']
}

task importMgdmHauptnutzung(type: Ili2pgImport, dependsOn: 'deleteMgdmLandUsesPlansData') {
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelMgdm
    dbschema = dbSchemaMgdmLandUsePlans
    dataset = 'catalogue_ch'
    dataFile = file("Nutzungsplanung_Catalogue_CH_V1_2_20210901.xml")
}

//Hier wird ein leeres XTF importiert, damit ein Basket vorhanden ist, auf den im nächsten Schritt dann referenziert werden kann. 
task importEmptyXtf(type: Ili2pgImport, dependsOn: 'importMgdmHauptnutzung') {
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelMgdm
    dbschema = dbSchemaMgdmLandUsePlans
    dataset = 'data'
    dataFile = file("arp_nutzungsplanung_empty.xtf")
}

task transferLandUsePlansData(type: SqlExecutor, dependsOn: 'importEmptyXtf') {
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ['arp_nutzungsplanung_mgdm.sql']
}

task exportMgdmLandUsePlans(type: Ili2pgExport, dependsOn: 'transferLandUsePlansData') {
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelMgdm
    dbschema = dbSchemaMgdmLandUsePlans
    dataFile = file(mgdmLandUsePlansXtfFileName)
    disableValidation = true
    dataset = 'data'  
}

task validateMgdmLandUsePlans(type: IliValidator, dependsOn: 'exportMgdmLandUsePlans') {
    dataFiles = [file("Nutzungsplanung_Catalogue_CH_V1_2_20210901.xml"), file(mgdmLandUsePlansXtfFileName)]
    if (findProperty('ilivalidatorModeldir')) modeldir = ilivalidatorModeldir
    logFile = "ilivalidator_landuseplans.log"
    allObjectsAccessible = true
    configFile = "config.toml"
    failOnError = true
}

task zipMgdmLandUsePlans(type: Zip, dependsOn: 'validateMgdmLandUsePlans'){
    from pathToTempFolder
    from "."
    include mgdmLandUsePlansXtfFileName
    include "config.toml"
    archiveName mgdmLandUsePlansZipFileName
    destinationDir(file(pathToTempFolder))
}

task uploadMgdmLandUsePlans(dependsOn: 'zipMgdmLandUsePlans') {

    def aiLogin = aiUser + ":" + aiPwd
    def zipFilePath = Paths.get(pathToTempFolder.toString(), mgdmLandUsePlansZipFileName)
    def serverUrl = "https://" + aiServer + "/data_agg/interlis/import"

    doLast {
        def response = ["curl", "-u", aiLogin, "-F", "topic=npl_nutzungsplanung_v1_2", "-F",
                        "lv95_file=@" + zipFilePath, "-F", "publish=true", "-F", "replace_all=false", serverUrl
                        ].execute().text

        println(response)
        if (response.contains("false") || response == null || response.trim().isEmpty()) {
            throw new GradleException()
        }
    }
}